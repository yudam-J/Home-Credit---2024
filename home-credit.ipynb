{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"},{"sourceId":8527768,"sourceType":"datasetVersion","datasetId":5092614},{"sourceId":8528249,"sourceType":"datasetVersion","datasetId":5092965}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/home-credit-00c58f22-7ff4-4e55-988b-3245f9e16425.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240527/auto/storage/goog4_request&X-Goog-Date=20240527T141040Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0be909e11f0c026a1bc9fee1298836bc80e6005f73e678f6a4ea9473b168554e5c3262f61a20fae08ef47d201fdad3263c208749e1819c99ea65a1021680e7615995d94bd6592ec91d2ed9f78183179c5d2ff59227f87a2973613ec0f4ffdd223137b0579261a882c986055b73c02ed84c18e1738e1ed3ffd4faa2451e7812c1f4eec907b0ca571e6a17d1d2ad554eb34c3fbcd2b3a5f9d6a35f964def73e4cc8aa4f2d58320124aaf6736899f280db049bed083636fc87cdad581d4bcc31f6f5dce3942b8cbc7ed8c5adc34c04b7319cdca3096fd7e971f73a57119cdf5ebe199331a4e2c2840c5f65ef4305b78e45ebc1bcc93a5dc17dbbe98773877e0f657","timestamp":1716820468906}],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["_awVbBKXY6D2","Lg8GXjI7Y6D4"]},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 함수","metadata":{"id":"-IKuClKcdwt_"}},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\n\ndef drop_columns_with_high_null(df, threshold=0.95):\n    \"\"\"\n    Polars 데이터프레임의 각 열마다 널값의 비율을 계산하여 threshold 이상이면 해당 열을 제거합니다.\n\n    Parameters:\n    df (pl.DataFrame): 널값 비율을 검사할 데이터프레임\n    threshold (float): 널값 비율의 임계값 (기본값은 0.95)\n\n    Returns:\n    pl.DataFrame: 지정된 비율 이상의 널값을 가진 열이 제거된 데이터프레임\n    \"\"\"\n    # 각 열마다 널값의 비율 계산\n    null_counts = df.null_count()\n    total_rows = df.shape[0]\n\n    # 널값 비율을 계산하고 임계값 이상의 널값 비율을 가진 열 선택\n    columns_to_drop = [\n        column for column in df.columns\n        if null_counts[column][0] / total_rows > threshold\n    ]\n\n    # 해당 열들을 데이터프레임에서 제거\n    df_cleaned = df.drop(columns_to_drop)\n\n    return df_cleaned, columns_to_drop\n\n## date타입 변환\n# 'D'로 끝나는 모든 컬럼에 대해 변환 수행\ndef datetype_preprocessing(df):\n    for col in df.columns:\n        if col.endswith('D'):\n            # Handle null values by filling them with an empty string or some default date string\n            df = df.with_columns(\n                pl.col(col).fill_null('').cast(pl.Utf8)\n            )\n\n            # Convert the string to date\n            df = df.with_columns(\n                pl.col(col).str.strptime(pl.Date, \"%Y-%m-%d\", strict=False)\n            )\n\n            # Convert the date to integer format YYYYMMDD\n            df = df.with_columns(\n                pl.col(col).cast(pl.Int32).fill_null(0).alias(col)\n            )\n    return df\n\n## lavel encoding\ndef label_encoding(df):\n    if isinstance(df, pl.DataFrame):\n        # Convert Polars dataframe to Pandas dataframe\n        df = df.to_pandas()\n    for column in df.columns:\n        # 판다스 데이터프레임에서 문자열 열 확인\n        if df[column].dtype == 'object':\n            le = LabelEncoder()\n            # 라벨 인코딩 수행\n            df[column] = le.fit_transform(df[column])\n    return df\n\n\n##null 값 선형회귀로 채우기\n\ndef linear_regression_imputation(data, target_column, reference_columns):\n    \"\"\"\n    데이터셋의 특정 칼럼의 결측치를 선형 회귀로 채웁니다.\n\n    Parameters:\n        data (DataFrame): 결측치를 채울 데이터셋\n        target_column (str): 결측치를 채울 대상 칼럼의 이름\n        reference_columns (list): 결측치를 채울 때 참고할 칼럼들의 이름 리스트\n\n    Returns:\n        DataFrame: 결측치가 채워진 데이터셋\n    \"\"\"\n    # 대상 칼럼과 참고할 칼럼들로 이루어진 subset 생성\n    subset = data[[target_column] + reference_columns]\n\n    # 결측치를 가진 행과 결측치가 아닌 행을 분리\n    missing_data = subset[subset[target_column].isnull()]\n    complete_data = subset.dropna(subset=[target_column])\n\n    # 선형 회귀 모델 학습\n    X = complete_data[reference_columns]\n    y = complete_data[target_column]\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # 결측치를 예측하여 채움\n    imputed_values = model.predict(missing_data[reference_columns])\n    data.loc[data[target_column].isnull(), target_column] = imputed_values\n\n    return data\n\n# 사용 예시\n# linear_regression_imputation(data, 'target_column', ['reference_column1', 'reference_column2'])\n\n##null 값 처리 함수\ndef null_preprocessing(df):\n    if isinstance(df, pl.DataFrame):\n        # Convert Polars dataframe to Pandas dataframe\n        df = df.to_pandas()\n    non_null_columns = [col for col in df.columns if df[col].notnull().all()]\n    null_columns = [col for col in df.columns if df[col].isnull().any()]\n\n    for column in null_columns:\n        print(column)\n        df = linear_regression_imputation(df, column, non_null_columns)\n    return df\n\ndef num_group_by(df):\n    # 각 그룹의 평균 계산\n    df_mean = df.groupby('case_id').mean()\n    df_mean.drop(['num_group1','num_group2'])\n    return df_mean\n\ndef find_all_null_columns(df):\n    all_null_columns = []\n    for col in df.columns:\n        if df.select(pl.col(col).is_null().sum()).item() == df.height:\n            all_null_columns.append(col)\n    return all_null_columns\n\ndef test_train_col_equ(train, test):\n    # 훈련 세트와 테스트 세트의 열 이름 가져오기\n    train_columns = set(train.columns)\n    test_columns = set(test.columns)\n\n    # 테스트 세트에만 있는 열 찾기\n    test_only_columns = test_columns - train_columns\n    print(f\"Columns only in test set: {test_only_columns}\")\n    test = test.drop(test_only_columns)\n\n    return test\n\n\n","metadata":{"id":"hlW9r8A7dlXZ","executionInfo":{"status":"ok","timestamp":1716826447808,"user_tz":-540,"elapsed":628,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"execution":{"iopub.status.busy":"2024-05-27T18:35:39.449910Z","iopub.execute_input":"2024-05-27T18:35:39.450247Z","iopub.status.idle":"2024-05-27T18:35:39.470298Z","shell.execute_reply.started":"2024-05-27T18:35:39.450223Z","shell.execute_reply":"2024-05-27T18:35:39.469122Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport re\nimport polars.selectors as cs\n\n\ndef train_static_depth0_preprocess(train_static):\n    if isinstance(train_static, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_static = pl.DataFrame(train_static)\n\n    #actualdpdtolerance_344P 삭제\n    train_static = train_static.drop(['actualdpdtolerance_344P'])\n    train_static = train_static.with_columns(\n        pl.when(train_static['annuity_780A'].is_not_null())\n        .then(train_static['annuity_780A'])\n        .otherwise(train_static['annuitynextmonth_57A'])\n        .alias('annuity')\n    )\n    train_static = train_static.drop(['annuity_780A'])\n    train_static = train_static.drop(['annuitynextmonth_57A'])\n    #applicationscnt\n    train_static = train_static.drop(['applicationcnt_361L','applications30d_658L','applicationscnt_1086L','applicationscnt_629L','applicationscnt_867L'])\n    train_static = train_static.drop(['avgdbddpdlast3m_4187120P'])\n    #전화번호 관련 열 다 삭제\n    # 'clientscnt'로 시작하는 모든 열을 찾습니다.\n    columns_to_drop = [column for column in train_static.columns if column.startswith('clientscnt')]\n    # 이 열들을 삭제합니다.\n    train_static = train_static.drop(columns_to_drop)\n    # 'commnoinclast6m_3546845L' 다 0임\n    train_static = train_static.drop('commnoinclast6m_3546845L')\n    train_static = train_static.drop(['currdebt_22A','currdebtcredtyperange_828A']) # 삭제\n    train_static = train_static.drop('homephncnt_628L') # 삭제\n    train_static = train_static.drop('maxdbddpdlast1m_3658939P') # 삭제\n    train_static = train_static.drop('maxdbddpdtollast6m_4187119P') # 삭제\n    train_static = train_static.drop(['maxdpdlast12m_727P','maxdpdlast3m_392P','maxdpdlast6m_474P','maxdpdlast9m_1059P','maxdpdlast24m_143P'])\n    train_static = train_static.drop('mobilephncnt_593L')\n\n    train_static = train_static.drop('interestrategrace_34L')\n    train_static = train_static.drop('equalityempfrom_62L')\n    train_static = train_static.drop('clientscnt_136L')\n    train_static = train_static.drop('lastdependentsnum_448L')\n    train_static = train_static.drop('lastotherinc_902A')\n    train_static = train_static.drop('lastotherlnsexpense_631A')\n    train_static = train_static.drop('lastrepayingdate_696D')\n    train_static = train_static.drop('maxannuity_4075009A')\n    train_static = train_static.drop('validfrom_1069D')\n\n    train_static = train_static.with_columns(\n        pl.when(train_static['sumoutstandtotal_3546847A'].is_not_null())\n        .then(train_static['sumoutstandtotal_3546847A'])\n        .otherwise(train_static['sumoutstandtotalest_4493215A'])\n        .alias('sumoutstandtotal')\n    )\n    train_static = train_static.drop('sumoutstandtotal_3546847A') # 삭제\n    train_static = train_static.drop('sumoutstandtotalest_4493215A') # 삭제\n\n    train_static, columns_to_drop = drop_columns_with_high_null(train_static,0.95)\n    train_static = datetype_preprocessing(train_static)\n    train_static = label_encoding(train_static)\n    train_static = null_preprocessing(train_static)\n\n    if isinstance(train_static, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_static = pl.DataFrame(train_static)\n\n    return train_static, columns_to_drop\n\n\n\ndef test_static_depth0_preprocess(test_static, columns_to_drop_in_train):\n    if isinstance(test_static, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_static = pl.DataFrame(test_static)\n\n    #actualdpdtolerance_344P 삭제\n    test_static = test_static.drop(['actualdpdtolerance_344P'])\n    test_static = test_static.with_columns(\n        pl.when(test_static['annuity_780A'].is_not_null())\n        .then(test_static['annuity_780A'])\n        .otherwise(test_static['annuitynextmonth_57A'])\n        .alias('annuity')\n    )\n    test_static = test_static.drop(['annuity_780A'])\n    test_static = test_static.drop(['annuitynextmonth_57A'])\n    #applicationscnt\n    test_static = test_static.drop(['applicationcnt_361L','applications30d_658L','applicationscnt_1086L','applicationscnt_629L','applicationscnt_867L'])\n    test_static = test_static.drop(['avgdbddpdlast3m_4187120P'])\n    #전화번호 관련 열 다 삭제\n    # 'clientscnt'로 시작하는 모든 열을 찾습니다.\n    columns_to_drop = [column for column in test_static.columns if column.startswith('clientscnt')]\n    # 이 열들을 삭제합니다.\n    test_static = test_static.drop(columns_to_drop)\n    # 'commnoinclast6m_3546845L' 다 0임\n    test_static = test_static.drop('commnoinclast6m_3546845L')\n    test_static = test_static.drop(['currdebt_22A','currdebtcredtyperange_828A']) # 삭제\n    test_static = test_static.drop('homephncnt_628L') # 삭제\n    test_static = test_static.drop('maxdbddpdlast1m_3658939P') # 삭제\n    test_static = test_static.drop('maxdbddpdtollast6m_4187119P') # 삭제\n    test_static = test_static.drop(['maxdpdlast12m_727P','maxdpdlast3m_392P','maxdpdlast6m_474P','maxdpdlast9m_1059P','maxdpdlast24m_143P'])\n    test_static = test_static.drop('mobilephncnt_593L')\n\n    test_static = test_static.drop('interestrategrace_34L')\n    test_static = test_static.drop('equalityempfrom_62L')\n    test_static = test_static.drop('clientscnt_136L')\n    test_static = test_static.drop('lastdependentsnum_448L')\n    test_static = test_static.drop('lastotherinc_902A')\n    test_static = test_static.drop('lastotherlnsexpense_631A')\n    test_static = test_static.drop('lastrepayingdate_696D')\n    test_static = test_static.drop('maxannuity_4075009A')\n    test_static = test_static.drop('validfrom_1069D')\n\n\n    test_static = test_static.with_columns(\n        pl.when(test_static['sumoutstandtotal_3546847A'].is_not_null())\n        .then(test_static['sumoutstandtotal_3546847A'])\n        .otherwise(test_static['sumoutstandtotalest_4493215A'])\n        .alias('sumoutstandtotal')\n    )\n    test_static = test_static.drop('sumoutstandtotal_3546847A') # 삭제\n    test_static = test_static.drop('sumoutstandtotalest_4493215A') # 삭제\n\n    test_static = test_static.drop(columns_to_drop_in_train)\n    test_static = datetype_preprocessing(test_static)\n    test_static = label_encoding(test_static)\n    test_static = null_preprocessing(test_static)\n\n\n    if isinstance(test_static, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_static = pl.DataFrame(test_static)\n\n    return test_static\n\n\ndef train_credit_bureau_a_depth2_preprocess(train_credit_bureau_a_2):\n\n    train_credit_bureau_a_2 = train_credit_bureau_a_2.with_columns(\n        (pl.col('collater_valueofguarantee_1124L') > 0).cast(pl.Int8).alias('collater_valueofguarantee_1124L')\n    )\n    train_credit_bureau_a_2['collater_valueofguarantee_1124L'].fill_null(0)\n\n    train_credit_bureau_a_2 = train_credit_bureau_a_2.with_columns(\n        (pl.col('collater_valueofguarantee_876L') > 0).cast(pl.Int8).alias('collater_valueofguarantee_876L')\n    )\n\n    train_credit_bureau_a_2, columns_to_drop = drop_columns_with_high_null(train_credit_bureau_a_2,0.95)\n    train_credit_bureau_a_2 = datetype_preprocessing(train_credit_bureau_a_2)\n    train_credit_bureau_a_2 = label_encoding(train_credit_bureau_a_2)\n    train_credit_bureau_a_2 = null_preprocessing(train_credit_bureau_a_2)\n\n    if isinstance(train_credit_bureau_a_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_credit_bureau_a_2 = pl.DataFrame(train_credit_bureau_a_2)\n\n    return train_credit_bureau_a_2, columns_to_drop\n\ndef test_credit_bureau_a_depth2_preprocess(test_credit_bureau_a_2, columns_to_drop_in_train):\n\n    test_credit_bureau_a_2 = test_credit_bureau_a_2.with_columns(\n        (pl.col('collater_valueofguarantee_1124L') > 0).cast(pl.Int8).alias('collater_valueofguarantee_1124L')\n    )\n    test_credit_bureau_a_2['collater_valueofguarantee_1124L'].fill_null(0)\n\n    test_credit_bureau_a_2 = test_credit_bureau_a_2.with_columns(\n        (pl.col('collater_valueofguarantee_876L') > 0).cast(pl.Int8).alias('collater_valueofguarantee_876L')\n    )\n\n    test_credit_bureau_a_2 = test_credit_bureau_a_2.drop(columns_to_drop_in_train)\n    test_credit_bureau_a_2 = datetype_preprocessing(test_credit_bureau_a_2)\n    test_credit_bureau_a_2 = label_encoding(test_credit_bureau_a_2)\n    test_credit_bureau_a_2 = null_preprocessing(test_credit_bureau_a_2)\n\n\n    if isinstance(test_credit_bureau_a_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_credit_bureau_a_2 = pl.DataFrame(test_credit_bureau_a_2)\n\n    return test_credit_bureau_a_2\n\n\ndef train_credit_bureau_b_depth2_preprocess(train_credit_bureau_b_2):\n    train_credit_bureau_b_2 = num_group_by(train_credit_bureau_b_2)\n    train_credit_bureau_b_2 = train_credit_bureau_b_2.drop(\"pmts_date_1107D\")\n    train_credit_bureau_b_2, columns_to_drop = drop_columns_with_high_null(train_credit_bureau_b_2,0.95)\n    train_credit_bureau_b_2 = datetype_preprocessing(train_credit_bureau_b_2)\n    train_credit_bureau_b_2 = label_encoding(train_credit_bureau_b_2)\n    train_credit_bureau_b_2 = null_preprocessing(train_credit_bureau_b_2)\n\n    if isinstance(train_credit_bureau_b_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_credit_bureau_b_2 = pl.DataFrame(train_credit_bureau_b_2)\n\n    return train_credit_bureau_b_2, columns_to_drop\n\ndef test_credit_bureau_b_depth2_preprocess(test_credit_bureau_b_2, columns_to_drop_in_train):\n    test_credit_bureau_b_2 = num_group_by(test_credit_bureau_b_2)\n\n    test_credit_bureau_b_2 = test_credit_bureau_b_2.drop(\"pmts_date_1107D\")\n\n    test_credit_bureau_b_2 = test_credit_bureau_b_2.drop(columns_to_drop_in_train)\n    test_credit_bureau_b_2 = datetype_preprocessing(test_credit_bureau_b_2)\n    test_credit_bureau_b_2 = label_encoding(test_credit_bureau_b_2)\n    test_credit_bureau_b_2 = null_preprocessing(test_credit_bureau_b_2)\n\n    if isinstance(test_credit_bureau_b_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_credit_bureau_b_2 = pl.DataFrame(test_credit_bureau_b_2)\n\n    return test_credit_bureau_b_2\n\n\ndef train_credit_person_depth2_preprocess(train_credit_person_2):\n    train_credit_person_2 = num_group_by(train_credit_person_2)\n    train_credit_person_2, columns_to_drop = drop_columns_with_high_null(train_credit_person_2,0.95)\n    train_credit_person_2 = datetype_preprocessing(train_credit_person_2)\n    train_credit_person_2 = label_encoding(train_credit_person_2)\n    train_credit_person_2 = null_preprocessing(train_credit_person_2)\n\n    if isinstance(train_credit_person_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_credit_person_2 = pl.DataFrame(train_credit_person_2)\n\n    return train_credit_person_2, columns_to_drop\n\ndef test_credit_person_depth2_preprocess(test_credit_person_2, columns_to_drop_in_train):\n    test_credit_person_2 = num_group_by(test_credit_person_2)\n    test_credit_person_2 = test_credit_person_2.drop(columns_to_drop_in_train)\n    test_credit_person_2 = datetype_preprocessing(test_credit_person_2)\n    test_credit_person_2 = label_encoding(test_credit_person_2)\n    test_credit_person_2 = null_preprocessing(test_credit_person_2)\n\n    if isinstance(test_credit_person_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_credit_person_2 = pl.DataFrame(test_credit_person_2)\n\n    return test_credit_person_2\n\ndef train_credit_applprev_depth2_preprocess(train_credit_applprev_2):\n    train_credit_applprev_2 = num_group_by(train_credit_applprev_2)\n    train_credit_applprev_2, columns_to_drop = drop_columns_with_high_null(train_credit_applprev_2,0.95)\n    train_credit_applprev_2 = datetype_preprocessing(train_credit_applprev_2)\n    train_credit_applprev_2 = label_encoding(train_credit_applprev_2)\n    train_credit_applprev_2 = null_preprocessing(train_credit_applprev_2)\n\n    if isinstance(train_credit_applprev_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_credit_applprev_2 = pl.DataFrame(train_credit_applprev_2)\n\n    return train_credit_applprev_2, columns_to_drop\n\ndef test_credit_applprev_depth2_preprocess(test_credit_applprev_2, columns_to_drop_in_train):\n    test_credit_applprev_2 = num_group_by(test_credit_applprev_2)\n\n    test_credit_applprev_2 = test_credit_applprev_2.drop(columns_to_drop_in_train)\n    test_credit_applprev_2 = datetype_preprocessing(test_credit_applprev_2)\n    test_credit_applprev_2 = label_encoding(test_credit_applprev_2)\n    test_credit_applprev_2 = null_preprocessing(test_credit_applprev_2)\n\n    if isinstance(test_credit_applprev_2, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_credit_applprev_2 = pl.DataFrame(test_credit_applprev_2)\n\n    return test_credit_applprev_2\n\n\n\ndef train_static_cb_depth0_preprocess(train_static_cb):\n    if isinstance(train_static_cb, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_static_cb = pl.DataFrame(train_static_cb)\n\n    #assignment\n    train_static_cb = train_static_cb.drop(['assignmentdate_238D','assignmentdate_4527235D','assignmentdate_4955616D'])\n\n\n\n    #days 어차피 누적되는 데이터 이므로 days360빼고 다 삭제해준다.\n    train_static_cb = train_static_cb.drop(['days30_165L','days90_310L','days120_123L','days180_256L'])\n\n\n    #fail for3years가 'formonth_118L','forquarter_462L','forweek_601L','foryear_618L'이 데이터를 모두 포함함\n    #'formonth_118L','forquarter_462L','forweek_601L','foryear_618L' drop\n    train_static_cb = train_static_cb.drop(['formonth_118L','forquarter_462L','forweek_601L','foryear_618L'])\n\n\n    # cancle for3years_584L가 'formonth _206L','forquarter_1017L','forweek_1077L','foryear_818L'이 데이터를 모두 포함함\n    # 'formonth _206L','forquarter_1017L','forweek_1077L','foryear_818L' drop\n    train_static_cb = train_static_cb.drop(['formonth_206L','forquarter_1017L','forweek_1077L','foryear_818L'])\n\n\n    # credit_history for3years가 'formonth_535L','forquarter_634L','forweek_528L','foryear_850L'이 데이터를 모두 포함함\n    # 'formonth_535L','forquarter_634L','forweek_528L','foryear_850L' drop\n    train_static_cb = train_static_cb.drop(['formonth_535L','forquarter_634L','forweek_528L','foryear_850L'])\n\n\n\n    #numberofqueries\n    train_static_cb = train_static_cb.drop('numberofqueries_373L') # 삭제\n\n\n\n    #4분기 실적만 남기기\n    train_static_cb = train_static_cb.drop('firstquarter_103L') # 삭제\n    train_static_cb = train_static_cb.drop('secondquarter_766L') # 삭제\n    train_static_cb = train_static_cb.drop('thirdquarter_1082L') # 삭제\n    train_static_cb = train_static_cb.with_columns(\n        train_static_cb['fourthquarter_440L'].fill_null(0)\n    )\n\n    train_static_cb, columns_to_drop = drop_columns_with_high_null(train_static_cb,0.95)\n    train_static_cb = datetype_preprocessing(train_static_cb)\n    train_static_cb = label_encoding(train_static_cb)\n    train_static_cb = null_preprocessing(train_static_cb)\n\n    if isinstance(train_static_cb, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        train_static_cb = pl.DataFrame(train_static_cb)\n\n    return train_static_cb, columns_to_drop\n\ndef test_static_cb_depth0_preprocess(test_static_cb, columns_to_drop_in_train):\n    if isinstance(test_static_cb, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_static_cb = pl.DataFrame(test_static_cb)\n\n     #assignment\n    test_static_cb = test_static_cb.drop(['assignmentdate_238D','assignmentdate_4527235D','assignmentdate_4955616D'])\n\n\n\n    #days 어차피 누적되는 데이터 이므로 days360빼고 다 삭제해준다.\n    test_static_cb = test_static_cb.drop(['days30_165L','days90_310L','days120_123L','days180_256L'])\n\n\n    #fail for3years가 'formonth_118L','forquarter_462L','forweek_601L','foryear_618L'이 데이터를 모두 포함함\n    #'formonth_118L','forquarter_462L','forweek_601L','foryear_618L' drop\n    test_static_cb = test_static_cb.drop(['formonth_118L','forquarter_462L','forweek_601L','foryear_618L'])\n\n\n    # cancle for3years_584L가 'formonth _206L','forquarter_1017L','forweek_1077L','foryear_818L'이 데이터를 모두 포함함\n    # 'formonth _206L','forquarter_1017L','forweek_1077L','foryear_818L' drop\n    test_static_cb = test_static_cb.drop(['formonth_206L','forquarter_1017L','forweek_1077L','foryear_818L'])\n\n\n    # credit_history for3years가 'formonth_535L','forquarter_634L','forweek_528L','foryear_850L'이 데이터를 모두 포함함\n    # 'formonth_535L','forquarter_634L','forweek_528L','foryear_850L' drop\n    test_static_cb = test_static_cb.drop(['formonth_535L','forquarter_634L','forweek_528L','foryear_850L'])\n\n\n\n    #numberofqueries\n    test_static_cb = test_static_cb.drop('numberofqueries_373L') # 삭제\n\n\n\n    #4분기 실적만 남기기\n    test_static_cb = test_static_cb.drop('firstquarter_103L') # 삭제\n    test_static_cb = test_static_cb.drop('secondquarter_766L') # 삭제\n    test_static_cb = test_static_cb.drop('thirdquarter_1082L') # 삭제\n    test_static_cb = test_static_cb.with_columns(\n        test_static_cb['fourthquarter_440L'].fill_null(0)\n    )\n\n    test_static_cb = test_static_cb.drop(columns_to_drop_in_train)\n    test_static_cb = datetype_preprocessing(test_static_cb)\n    test_static_cb = label_encoding(test_static_cb)\n    test_static_cb = null_preprocessing(test_static_cb)\n\n    if isinstance(test_static_cb, pd.DataFrame):\n        # pandas DataFrame을 polars DataFrame으로 변환\n        test_static_cb = pl.DataFrame(test_static_cb)\n\n    return test_static_cb","metadata":{"id":"Xii5QkLJdo7y","executionInfo":{"status":"ok","timestamp":1716826448445,"user_tz":-540,"elapsed":3,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"execution":{"iopub.status.busy":"2024-05-27T18:34:34.254850Z","iopub.execute_input":"2024-05-27T18:34:34.255234Z","iopub.status.idle":"2024-05-27T18:34:34.307916Z","shell.execute_reply.started":"2024-05-27T18:34:34.255203Z","shell.execute_reply":"2024-05-27T18:34:34.306967Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def datetype_preprocessing(df):\n    for col in df.columns:\n        if col.endswith('D'):\n            # Fill null values with an empty string or a default date string\n            df[col] = df[col].astype(str).fillna('')\n\n            # Convert the string to datetime, errors='coerce' will turn invalid parsing into NaT\n            df[col] = pd.to_datetime(df[col], format=\"%Y-%m-%d\", errors='coerce')\n\n            # Convert the date to integer format YYYYMMDD\n            df[col] = df[col].dt.strftime('%Y%m%d').fillna('0').astype(int)\n\n    return df\n\ndef column_description(df, column):\n    feature_definitions = pd.read_csv(dataPath + 'feature_definitions.csv')\n    definition = feature_definitions[feature_definitions['Variable'] == column]\n    return definition\n\ndef calculate_missing_percentage(dataframe):\n    \"\"\"\n    데이터프레임의 각 열에 대한 결측치 비율을 계산하고 오름차순으로 정렬하는 함수\n\n    Parameters:\n    dataframe (DataFrame): 결측치를 계산할 데이터프레임\n\n    Returns:\n    DataFrame: 각 열에 대한 결측치 비율이 포함된 데이터프레임\n    \"\"\"\n    total_rows = len(dataframe)\n    missing_count = dataframe.isnull().sum()\n    missing_percentage = (missing_count / total_rows) * 100\n    missing_data = pd.DataFrame({\n        'Column': dataframe.columns,\n        'Missing': missing_count,\n        'Percent': missing_percentage\n    }).reset_index(drop=True)\n\n    # 결측치 비율에 따라 오름차순으로 정렬\n    missing_data = missing_data.sort_values(by='Percent', ascending=True).reset_index(drop=True)\n\n    return missing_data\n\ndef date_to_integer(df, column):\n    df[column] = pd.to_datetime(df[column], errors='coerce')\n    df[column+'int'] = df[column].dt.strftime('%Y%m%d').fillna('0').astype(int)\n    df = df.drop(columns=[column])\n    return df\n\ndef drop_columns(dataframe, threshold=80):\n    \"\"\"\n    결측치 비율이 주어진 임계값을 초과하는 열을 삭제하는 함수\n\n    Parameters:\n    dataframe (DataFrame): 결측치를 확인할 데이터프레임\n    threshold (float): 결측치 비율 임계값 (기본값: 80)\n\n    Returns:\n    DataFrame: 지정된 임계값 이상의 결측치를 가진 열이 삭제된 데이터프레임\n    \"\"\"\n    missing_data = calculate_missing_percentage(dataframe)\n    columns_to_drop = missing_data[missing_data['Percent'] > threshold]['Column']\n    dataframe_dropped = dataframe.drop(columns=columns_to_drop)\n    return dataframe_dropped\n\nfrom sklearn.linear_model import LinearRegression\n\ndef linear_regression_imputation(data, target_column, reference_columns):\n    \"\"\"\n    데이터셋의 특정 칼럼의 결측치를 선형 회귀로 채웁니다.\n\n    Parameters:\n        data (DataFrame): 결측치를 채울 데이터셋\n        target_column (str): 결측치를 채울 대상 칼럼의 이름\n        reference_columns (list): 결측치를 채울 때 참고할 칼럼들의 이름 리스트\n\n    Returns:\n        DataFrame: 결측치가 채워진 데이터셋\n    \"\"\"\n    # 대상 칼럼과 참고할 칼럼들로 이루어진 subset 생성\n    subset = data[[target_column] + reference_columns]\n\n    # 결측치를 가진 행과 결측치가 아닌 행을 분리\n    missing_data = subset[subset[target_column].isnull()]\n    complete_data = subset.dropna(subset=[target_column])\n\n    # 선형 회귀 모델 학습\n    X = complete_data[reference_columns]\n    y = complete_data[target_column]\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # 결측치를 예측하여 채움\n    imputed_values = model.predict(missing_data[reference_columns])\n    data.loc[data[target_column].isnull(), target_column] = imputed_values\n\n    return data\n\n# 사용 예시\n# linear_regression_imputation(data, 'target_column', ['reference_column1', 'reference_column2'])\n\ndef columns_with_no_missing_values(df):\n    \"\"\"\n    데이터프레임에서 결측치 개수가 0인 열의 이름을 반환하는 함수\n\n    Parameters:\n    df (DataFrame): 검사할 데이터프레임\n\n    Returns:\n    list: 결측치 개수가 0인 열의 이름을 담은 리스트\n    \"\"\"\n    missing_data = calculate_missing_percentage(df)\n    return missing_data[missing_data['Missing'] == 0].index.tolist()\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encode_column(data, column_name):\n    \"\"\"\n    Label encode a column in the DataFrame.\n\n    Parameters:\n    - data: DataFrame containing the column to be label encoded.\n    - column_name: Name of the column to be label encoded.\n\n    Returns:\n    - DataFrame with the specified column label encoded.\n    \"\"\"\n    # Label encode the column\n    label_encoder = LabelEncoder()\n    data[column_name] = label_encoder.fit_transform(data[column_name])\n\n    return data\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encoding(df):\n    if isinstance(df, pl.DataFrame):\n        # Convert Polars dataframe to Pandas dataframe\n        df = df.to_pandas()\n    elif not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a Pandas DataFrame or a Polars DataFrame\")\n\n    for column in df.columns:\n        # Check if the column is of object type\n        if df[column].dtype == 'object':\n            le = LabelEncoder()\n            # Perform label encoding\n            df[column] = le.fit_transform(df[column])\n\n    if isinstance(df, pl.DataFrame):\n        # Convert back to Polars DataFrame if the original input was Polars\n        df = pl.DataFrame(df)\n\n    return df\n\ndef null_preprocessing(df):\n    if isinstance(df, pl.DataFrame):\n        # Convert Polars dataframe to Pandas dataframe\n        df = df.to_pandas()\n    non_null_columns = [col for col in df.columns if df[col].notnull().all()]\n    null_columns = [col for col in df.columns if df[col].isnull().any()]\n\n    for column in null_columns:\n        print(column)\n        df = linear_regression_imputation(df, column, non_null_columns)\n    return df\n\ndef replace_boolean_with_numeric(df):\n    # 데이터프레임 내의 모든 True를 1로, False를 0으로 바꿈\n    df = df.replace({True: 1, False: 0})\n    return df\n\nfrom sklearn.impute import KNNImputer\n\ndef knn_imputer_column(df, column_name, n_neighbors=3):\n    \"\"\"\n    선택한 열에 대해서만 KNN 기반 결측치 대체를 수행하는 함수\n\n    :param df: 데이터프레임\n    :param column_name: 대체하고자 하는 열의 이름\n    :param n_neighbors: KNN 알고리즘에서 이웃의 수\n    :return: 선택한 열의 결측치가 대체된 시리즈\n    \"\"\"\n    # 대상 열만 있는 데이터프레임 생성\n    df_subset = df[[column_name]]\n\n    # KNNImputer 객체 생성\n    imputer = KNNImputer(n_neighbors=n_neighbors)\n\n    # 결측치 대체\n    filled_array = imputer.fit_transform(df_subset)\n\n    # 대체된 값을 시리즈로 변환\n    filled_series = pd.Series(filled_array[:, 0], name=column_name, index=df.index)\n\n    return filled_series\n\n\nimport pandas as pd\n\ndef merge_columns(df, common_name, col_1, col_2):\n    temp_df_1 = df[['case_id', 'num_group1', col_1]].copy()\n    temp_df_1.dropna(subset=[col_1], inplace=True)\n    temp_df_1.rename(columns={col_1: common_name}, inplace=True)\n\n    temp_df_2 = df[['case_id', 'num_group1', col_2]].copy()\n    temp_df_2.dropna(subset=[col_2], inplace=True)\n    temp_df_2.rename(columns={col_2: common_name}, inplace=True)\n\n    merged_df = pd.concat([temp_df_1, temp_df_2])\n    merged_df.drop_duplicates(subset=['case_id', 'num_group1'], inplace=True)\n\n    df = pd.merge(df, merged_df, how='outer', on=['case_id', 'num_group1'])\n\n    df.drop(columns=col_1, inplace=True)\n    df.drop(columns=col_2, inplace=True)\n\n    return df\n\nimport pandas as pd\n\ndef find_missing_rows(df, column_name):\n    \"\"\"\n    데이터프레임의 특정 열의 결측치의 행 번호를 반환하는 함수\n\n    :param df: 데이터프레임\n    :param column_name: 결측치를 확인할 열의 이름\n    :return: 결측치가 있는 행의 번호 리스트\n    \"\"\"\n    missing_rows = df[df[column_name].isnull()].index.tolist()\n    return missing_rows","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install fastparquet\n!pip install pyarrow\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhzAMviCmcOe","executionInfo":{"status":"ok","timestamp":1716826458160,"user_tz":-540,"elapsed":9718,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"ce6d9aaa-92e0-42cf-baa5-d4454ef95f12","execution":{"iopub.status.busy":"2024-05-27T18:02:24.248497Z","iopub.execute_input":"2024-05-27T18:02:24.249119Z","iopub.status.idle":"2024-05-27T18:02:49.296630Z","shell.execute_reply.started":"2024-05-27T18:02:24.249062Z","shell.execute_reply":"2024-05-27T18:02:49.295289Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: fastparquet in /opt/conda/lib/python3.10/site-packages (2024.5.0)\nRequirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from fastparquet) (2.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fastparquet) (1.26.4)\nRequirement already satisfied: cramjam>=2.3 in /opt/conda/lib/python3.10/site-packages (from fastparquet) (2.8.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from fastparquet) (2024.2.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastparquet) (21.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2023.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fastparquet) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (15.0.2)\nRequirement already satisfied: numpy<2,>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pyarrow) (1.26.4)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 0. package import","metadata":{"id":"y7WVPAYyY6D1"}},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport gc\ndataPath = \"/kaggle/input/home-credit-credit-risk-model-stability/\"","metadata":{"id":"uE--xJPEY6D2","executionInfo":{"status":"ok","timestamp":1716826793947,"user_tz":-540,"elapsed":512,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"execution":{"iopub.status.busy":"2024-05-27T18:02:49.298389Z","iopub.execute_input":"2024-05-27T18:02:49.298809Z","iopub.status.idle":"2024-05-27T18:02:49.309653Z","shell.execute_reply.started":"2024-05-27T18:02:49.298766Z","shell.execute_reply":"2024-05-27T18:02:49.308706Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 1. data load","metadata":{"id":"bsab8LjpY6D2"}},{"cell_type":"code","source":"def downcast_df(df):\n    # Integer columns downcast\n    int_cols = df.select_dtypes(include=['int64', 'int32', 'int16', 'int8']).columns\n    for col in int_cols:\n        df[col] = df[col].astype('int16')\n\n    # Float columns downcast\n    float_cols = df.select_dtypes(include=['float64', 'float32']).columns\n    for col in float_cols:\n        df[col] = df[col].astype('float32')\n\n    return df","metadata":{"id":"oBt_iVfqnWD6","executionInfo":{"status":"ok","timestamp":1716826795748,"user_tz":-540,"elapsed":396,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"execution":{"iopub.status.busy":"2024-05-27T18:02:49.311913Z","iopub.execute_input":"2024-05-27T18:02:49.312268Z","iopub.status.idle":"2024-05-27T18:02:49.317852Z","shell.execute_reply.started":"2024-05-27T18:02:49.312235Z","shell.execute_reply":"2024-05-27T18:02:49.316908Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## depth2 - 1/3","metadata":{"id":"mJhJb1WKY6D3"}},{"cell_type":"code","source":"import cudf\n\n# Initialize an empty dataframe for concatenation\ncombined_df = None\n\n# Process files in batches to manage memory usage\nfor i in range(0,6):\n    gc.collect()\n    print(i)\n    # Read the parquet file using cudf\n    df = cudf.read_parquet(f\"{dataPath}parquet_files/train/train_credit_bureau_a_2_{i}.parquet\")\n    \n    # Convert the cudf DataFrame to pandas DataFrame\n    df_pd = df.to_pandas()\n    del df\n    # Downcast the pandas DataFrame\n    df_downcasted = downcast_df(df_pd)\n    del df_pd\n    # Concatenate the downcasted pandas DataFrame\n    if combined_df is None:\n        combined_df = df_downcasted\n    else:\n        combined_df = pd.concat([combined_df, df_downcasted], axis=0)\n        \n    # Explicitly delete the temporary DataFrame to free memory\n    del df_downcasted\n    gc.collect()\n\n# Now you can continue working with the combined DataFrame\ntrain_credit_bureau_a_2_0_5 = combined_df\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgjYoSvbiWK2","executionInfo":{"status":"ok","timestamp":1716827164817,"user_tz":-540,"elapsed":357238,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"c701459a-a32e-42dd-ab0b-31252999eb75","execution":{"iopub.status.busy":"2024-05-27T18:03:17.108299Z","iopub.execute_input":"2024-05-27T18:03:17.108696Z","iopub.status.idle":"2024-05-27T18:05:31.540799Z","shell.execute_reply.started":"2024-05-27T18:03:17.108662Z","shell.execute_reply":"2024-05-27T18:05:31.539992Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/cudf/utils/_numba.py:110: UserWarning: Using CUDA toolkit version (12, 4) with CUDA driver version (12, 2) requires minor version compatibility, which is not yet supported for CUDA driver versions 12.0 and above. It is likely that many cuDF operations will not work in this state. Please install CUDA toolkit version (12, 2) to continue using cuDF.\n  warnings.warn(\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n","output_type":"stream"},{"name":"stdout","text":"0\n","output_type":"stream"},{"name":"stderr","text":"get_mempolicy: Operation not permitted\n","output_type":"stream"},{"name":"stdout","text":"1\n2\n3\n4\n5\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjUQzGJZ371S","executionInfo":{"status":"ok","timestamp":1716827198415,"user_tz":-540,"elapsed":462,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"87021686-5298-4924-d1aa-0b308d0039a5","execution":{"iopub.status.busy":"2024-05-27T18:05:49.885679Z","iopub.execute_input":"2024-05-27T18:05:49.886011Z","iopub.status.idle":"2024-05-27T18:05:50.032438Z","shell.execute_reply.started":"2024-05-27T18:05:49.885985Z","shell.execute_reply":"2024-05-27T18:05:50.031450Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"960"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize an empty dataframe for concatenation\ncombined_df = None\n\n# Process files in batches to manage memory usage\nfor i in range(12):\n    gc.collect()\n    print(i)\n    df = pl.read_parquet(f\"{dataPath}parquet_files/test/test_credit_bureau_a_2_{i}.parquet\")\n    df_pd = df.to_pandas()\n    df_downcasted = downcast_df(df_pd)\n\n    if combined_df is None:\n        combined_df = df_downcasted\n    else:\n        combined_df = pd.concat([combined_df, df_downcasted], axis=0)\n        # Explicitly delete the temporary dataframe to free memory\n        del df_pd, df_downcasted, df\n\n# Convert the combined dataframe back to Polars dataframe\ntest_credit_bureau_a_2 = pl.from_pandas(combined_df)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7Cbww6E4J75","executionInfo":{"status":"ok","timestamp":1716827270300,"user_tz":-540,"elapsed":1410,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"49903fee-4fe5-44e8-8cc8-4acbf5f1e7a5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_credit_bureau_b_2 = pl.read_parquet(dataPath + \"parquet_files/train/train_credit_bureau_b_2.parquet\")\ntest_credit_bureau_b_2 = pl.read_parquet(dataPath + \"parquet_files/test/test_credit_bureau_b_2.parquet\")","metadata":{"id":"COOeA7CNlcg7","executionInfo":{"status":"ok","timestamp":1716827319155,"user_tz":-540,"elapsed":744,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## depth0","metadata":{"id":"V60NovmIY6D2"}},{"cell_type":"code","source":"#train\ntrain_basetable = pl.read_parquet(dataPath + \"parquet_files/train/train_base.parquet\")\ntrain_static = pl.concat(\n    [\n        pl.read_parquet(dataPath + \"parquet_files/train/train_static_0_0.parquet\"),\n        pl.read_parquet(dataPath + \"parquet_files/train/train_static_0_1.parquet\"),\n    ],\n    how=\"vertical_relaxed\",\n)\ntrain_static = train_static.to_pandas()\ntrain_static = downcast_df(train_static)\ntrain_static = pl.DataFrame(train_static)\n\ntrain_static_cb = pl.read_parquet(dataPath + \"parquet_files/train/train_static_cb_0.parquet\")\ntrain_static_cb = train_static_cb.to_pandas()\ntrain_static_cb = downcast_df(train_static_cb)\ntrain_static_cb = pl.DataFrame(train_static_cb)\n\n#test\ntest_basetable = pl.read_parquet(dataPath + \"parquet_files/test/test_base.parquet\")\ntest_static = pl.concat(\n    [\n        pl.read_parquet(dataPath + \"parquet_files/test/test_static_0_0.parquet\"),\n        pl.read_parquet(dataPath + \"parquet_files/test/test_static_0_1.parquet\"),\n        pl.read_parquet(dataPath + \"parquet_files/test/test_static_0_2.parquet\"),\n    ],\n    how=\"vertical_relaxed\",\n)\ntest_static = test_static.to_pandas()\ntest_static = downcast_df(test_static)\ntest_static = pl.DataFrame(test_static)\n\ntest_static_cb = pl.read_parquet(dataPath + \"parquet_files/test/test_static_cb_0.parquet\")\ntest_static_cb = test_static_cb.to_pandas()\ntest_static_cb = downcast_df(test_static_cb)\n","metadata":{"id":"4DjfDAp8Y6D2","executionInfo":{"status":"ok","timestamp":1716827763387,"user_tz":-540,"elapsed":15396,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMk_G-o_xNnw","executionInfo":{"status":"ok","timestamp":1716827764904,"user_tz":-540,"elapsed":4,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"bf6884a1-c915-4254-e274-b98ad17a9d5d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## depth1","metadata":{"id":"_awVbBKXY6D2"}},{"cell_type":"code","source":"#train\ntrain_applprev_1 = pl.concat(\n    [\n        pl.read_parquet(dataPath + \"parquet_files/train/train_base.parquet\"),\n        pl.read_parquet(dataPath + \"train_applprev_1_1.parquet\"),\n    ],\n    how=\"vertical_relaxed\",\n)\ntrain_bureau_a_1_0 = pl.read_parquet(\"parquet_files/train/train_credit_bureau_a_1_0.parquet\")\ntrain_bureau_a_1_1 = pl.read_parquet(\"parquet_files/train/train_credit_bureau_a_1_1.parquet\")\ntrain_bureau_a_1_2 = pl.read_parquet(\"parquet_files/train/train_credit_bureau_a_1_2.parquet\")\ntrain_bureau_a_1_3 = pl.read_parquet(\"parquet_files/train/train_credit_bureau_a_1_3.parquet\")\ntrain_bureau_b_1 = pl.read_parquet(dataPath + \"/train_credit_bureau_b_1.parquet\")\ntrain_debitcard_1 = pl.read_parquet(dataPath + \"train_debitcard_1.parquet\")\ntrain_deposit_1 = pl.read_parquet(dataPath + \"train_deposit_1.parquet\")\ntrain_other_1 = pl.read_parquet(dataPath + \"train_other_1.parquet\")\ntrain_person_1 = pl.read_parquet(dataPath + \"train_person_1.parquet\")\ntrain_tax_registry_a_1 = pl.read_parquet(dataPath + \"train_tax_registry_a_1.parquet\")\ntrain_tax_registry_b_1 = pl.read_parquet(dataPath + \"train_tax_registry_b_1.parquet\")\ntrain_tax_registry_c_1 = pl.read_parquet(dataPath + \"train_tax_registry_c_1.parquet\")\n\n#test\ntest_applprev = pl.concat(\n    [\n        pl.read_parquet(dataPath + \"test_applprev_1_0.parquet\"),\n        pl.read_parquet(dataPath + \"test_applprev_1_1.parquet\"),\n        pl.read_parquet(dataPath + \"test_applprev_1_2.parquet\"),\n    ],\n    how=\"vertical_relaxed\",\n)\n\ntest_bureau_a = pl.concat(\n    [\n        pl.read_parquet(dataPath + \"test_credit_bureau_a_1_0.parquet\"),\n        pl.read_parquet(dataPath + \"test_credit_bureau_a_1_1.parquet\"),\n        pl.read_parquet(dataPath + \"test_credit_bureau_a_1_2.parquet\"),\n        pl.read_parquet(dataPath + \"test_credit_bureau_a_1_3.parquet\"),\n        pl.read_parquet(dataPath + \"test_credit_bureau_a_1_4.parquet\"),\n    ],\n    how=\"vertical_relaxed\",\n)\n\ntest_bureau_b_1 = pl.read_parquet(dataPath + \"test_credit_bureau_b_1.parquet\")\n\ntest_debitcard_1 = pl.read_parquet(dataPath + \"test_debitcard_1.parquet\")\ntest_deposit_1 = pl.read_parquet(dataPath + \"test_deposit_1.parquet\")\ntest_other_1 = pl.read_parquet(dataPath + \"test_other_1.parquet\")\ntest_person_1 = pl.read_parquet(dataPath + \"test_person_1.parquet\")\n\ntest_tax_registry_a_1 = pl.read_parquet(dataPath + \"test_tax_registry_a_1.parquet\")\ntest_tax_registry_b_1 = pl.read_parquet(dataPath + \"test_tax_registry_b_1.parquet\")\ntest_tax_registry_c_1 = pl.read_parquet(dataPath + \"test_tax_registry_c_1.parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T18:33:07.878750Z","iopub.execute_input":"2024-05-27T18:33:07.879119Z","iopub.status.idle":"2024-05-27T18:33:08.241387Z","shell.execute_reply.started":"2024-05-27T18:33:07.879087Z","shell.execute_reply":"2024-05-27T18:33:08.240152Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_applprev_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[1;32m      4\u001b[0m         pl\u001b[38;5;241m.\u001b[39mread_parquet(dataPath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet_files/train/train_base.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m         pl\u001b[38;5;241m.\u001b[39mread_parquet(dataPath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_applprev_1_1.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     ],\n\u001b[1;32m      7\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical_relaxed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m train_bureau_a_1_0 \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet_files/train/train_credit_bureau_a_1_0.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m train_bureau_a_1_1 \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet_files/train/train_credit_bureau_a_1_1.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"],"ename":"NameError","evalue":"name 'pl' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"# 2. data preprocessing","metadata":{"id":"ldauGepMY6D3"}},{"cell_type":"markdown","source":"## depth0 preprocessing","metadata":{"id":"d3Q7MTAsY6D4"}},{"cell_type":"markdown","source":"### static","metadata":{"id":"VlCHjSZBY6D4"}},{"cell_type":"code","source":"# 모든 값이 null인 열 찾기\nnull_columns = find_all_null_columns(test_static)\ntrain_static = train_static.drop(null_columns)\ntest_static = test_static.drop(null_columns)","metadata":{"id":"qPcT3L5iY6D4","executionInfo":{"status":"ok","timestamp":1716827771573,"user_tz":-540,"elapsed":390,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_static, train_static_columns_to_drop = train_static_depth0_preprocess(train_static)","metadata":{"id":"PXPMXvEvY6D4","outputId":"10f9c740-46c0-42ec-c725-813418dc3c3e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828087998,"user_tz":-540,"elapsed":315078,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvJSFEL4498C","executionInfo":{"status":"ok","timestamp":1716828087998,"user_tz":-540,"elapsed":8,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"018153ea-2a2b-4409-accc-ed3785e2fe18","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_static = test_static_depth0_preprocess(test_static, train_static_columns_to_drop)","metadata":{"id":"2qzpZqZpY6D4","outputId":"7ee53fe4-1e53-4ff1-8d00-0eca33335170","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828088660,"user_tz":-540,"elapsed":663,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_static = test_train_col_equ(train_static,test_static)","metadata":{"id":"giiUewFXY6D4","outputId":"2a5271c7-2d52-4872-cd6b-776ddaf91349","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828088661,"user_tz":-540,"elapsed":6,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### static_cb","metadata":{"id":"lh4BlbVQY6D4"}},{"cell_type":"code","source":"test_static_cb = pl.from_pandas(test_static_cb)","metadata":{"id":"mYc4Sm3b7tfG","executionInfo":{"status":"ok","timestamp":1716828230620,"user_tz":-540,"elapsed":445,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모든 값이 null인 열 찾기\nnull_columns = find_all_null_columns(test_static_cb)\ntrain_static_cb = train_static_cb.drop(null_columns)\ntest_static_cb = test_static_cb.drop(null_columns)","metadata":{"id":"5mJvF6nMY6D4","executionInfo":{"status":"ok","timestamp":1716828233040,"user_tz":-540,"elapsed":620,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_static_cb, train_static_cb_columns_to_drop = train_static_cb_depth0_preprocess(train_static_cb)","metadata":{"id":"Axo81SJ2Y6D4","outputId":"046e0014-9650-4179-da46-809f30213422","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828239036,"user_tz":-540,"elapsed":2614,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_static_cb = test_static_cb_depth0_preprocess(test_static_cb, train_static_cb_columns_to_drop)","metadata":{"id":"vzTLM3F5Y6D4","outputId":"7d017541-d5fe-45d7-e837-060a775d48f2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828241243,"user_tz":-540,"elapsed":491,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_static_cb = test_train_col_equ(train_static_cb,test_static_cb)","metadata":{"id":"ZXmBOpuJY6D4","outputId":"a274c393-e6fd-4036-8f6f-f59fa4a02d78","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828243557,"user_tz":-540,"elapsed":683,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_static_cb = test_static_cb.to_pandas()\ntrain_static_cb = train_static_cb.to_pandas()\n\ntest_static = test_static.to_pandas()\ntrain_static = train_static.to_pandas()","metadata":{"id":"q0ZErpRwY6D4","executionInfo":{"status":"ok","timestamp":1716828244777,"user_tz":-540,"elapsed":534,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## depth 1","metadata":{"id":"Lg8GXjI7Y6D4"}},{"cell_type":"markdown","source":"## depth2","metadata":{"id":"bzBUJZA5Y6D8"}},{"cell_type":"markdown","source":"applprev_depth2는 제외","metadata":{"id":"AcSI-xflY6D8"}},{"cell_type":"markdown","source":"- credit_bureau_a_2","metadata":{"id":"HGP_eYWIY6D8"}},{"cell_type":"code","source":"# 모든 값이 null인 열 찾기\nnull_columns = find_all_null_columns(test_credit_bureau_a_2)\ntrain_credit_bureau_a_2_0 = train_credit_bureau_a_2.drop(null_columns)\ntest_credit_bureau_a_2_0 = test_credit_bureau_a_2.drop(null_columns)","metadata":{"id":"Sgzh0xWrY6D9","executionInfo":{"status":"ok","timestamp":1716828253413,"user_tz":-540,"elapsed":551,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def num_group_by_0(df):\n    # 각 그룹의 평균 계산\n    df_mean = df.groupby('case_id').mean()\n    df_mean.drop(['num_group1','num_group2'])\n    return df_mean","metadata":{"id":"y-1CHfOLY6D9","executionInfo":{"status":"ok","timestamp":1716828257305,"user_tz":-540,"elapsed":618,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_credit_bureau_a_2_0_mean = num_group_by_0(train_credit_bureau_a_2_0)\ntrain_credit_bureau_a_2_0_mean","metadata":{"id":"cZymz8YyY6D9","outputId":"74e4676b-4fe3-4aa3-fbee-8c1f68400eb4","colab":{"base_uri":"https://localhost:8080/","height":938},"executionInfo":{"status":"ok","timestamp":1716828262996,"user_tz":-540,"elapsed":3286,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_credit_bureau_a_2_0_mean = num_group_by_0(test_credit_bureau_a_2_0)\ntest_credit_bureau_a_2_0_mean.tail(10)","metadata":{"id":"ckcnzOh2Y6D9","outputId":"83a3fcd2-df9a-46ab-e1ad-a7f5298da568","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1716828268442,"user_tz":-540,"elapsed":665,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ws4-5AT8Ioh","executionInfo":{"status":"ok","timestamp":1716828313554,"user_tz":-540,"elapsed":428,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"1903f0c9-4a18-4421-a002-2288db4287c4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_credit_bureau_a_2_0_mean, train_credit_bureau_a_columns_to_drop = train_credit_applprev_depth2_preprocess(train_credit_bureau_a_2_0_mean)","metadata":{"id":"fdto7IAKY6D9","outputId":"51850686-c2c3-49ac-e203-ea2951378c9a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828321121,"user_tz":-540,"elapsed":3995,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_credit_bureau_a_2_0_mean = test_credit_applprev_depth2_preprocess(test_credit_bureau_a_2_0_mean, train_credit_bureau_a_columns_to_drop)","metadata":{"id":"Gvk0QsZcY6D9","outputId":"fcaa6d2f-28dd-4286-ce54-0dfc1c2ea5fc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716828322895,"user_tz":-540,"elapsed":3,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_credit_bureau_a_2_0_mean['case_id'].tail(10)","metadata":{"id":"g86Z3uLEY6D9","outputId":"e1d7c7a0-d2aa-4823-da26-d0b2c35449b7","colab":{"base_uri":"https://localhost:8080/","height":412},"executionInfo":{"status":"ok","timestamp":1716828361896,"user_tz":-540,"elapsed":403,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## (1) data set 합치기","metadata":{"id":"wee8Gg_DY6D9"}},{"cell_type":"markdown","source":"### depth0","metadata":{"id":"4lJPqYQjY6D9"}},{"cell_type":"code","source":"train_basetable_temp = train_basetable.to_pandas()\ntest_basetable_temp = test_basetable.to_pandas()","metadata":{"id":"4_usXaolY6D9","executionInfo":{"status":"ok","timestamp":1716828395240,"user_tz":-540,"elapsed":963,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# object 타입인 열들을 찾음\nobject_columns_test = test_basetable_temp.select_dtypes(include=['object']).columns\nobject_columns_train = train_basetable_temp.select_dtypes(include=['object']).columns\n\n# object 타입인 열들을 제거\ntest_basetable_temp = test_basetable_temp.drop(columns=object_columns_test)\ntrain_basetable_temp = train_basetable_temp.drop(columns=object_columns_train)","metadata":{"id":"JoW7-iNVY6D9","executionInfo":{"status":"ok","timestamp":1716828406660,"user_tz":-540,"elapsed":560,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_static = pl.DataFrame(train_static)\ntrain_static_cb = pl.DataFrame(train_static_cb)\ntest_static = pl.DataFrame(test_static)\ntest_static_cb = pl.DataFrame(test_static_cb)","metadata":{"id":"hsR6SOgeY6D9","executionInfo":{"status":"ok","timestamp":1716828413335,"user_tz":-540,"elapsed":1166,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_static = train_static.to_pandas()\ntrain_static_cb = train_static_cb.to_pandas()\ntest_static = test_static.to_pandas()\ntest_static_cb = test_static_cb.to_pandas()","metadata":{"id":"rNlp3oeoY6D-","executionInfo":{"status":"ok","timestamp":1716828417141,"user_tz":-540,"elapsed":434,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"depth_0_train = pd.merge(train_static, train_static_cb, on='case_id', how='inner')\ndepth_0_test = pd.merge(test_static, test_static_cb, on='case_id', how='left')","metadata":{"id":"yClbXbFSY6D-","executionInfo":{"status":"ok","timestamp":1716828425451,"user_tz":-540,"elapsed":1492,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_depth_0_train = pd.merge(train_basetable_temp, depth_0_train, on='case_id', how='inner')\nbase_depth_0_test = pd.merge(test_basetable_temp, depth_0_test, on='case_id', how='left')","metadata":{"id":"IjhGrFDLY6D-","executionInfo":{"status":"ok","timestamp":1716828430370,"user_tz":-540,"elapsed":1767,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_depth_0_train","metadata":{"id":"QNrdAtEUY6D-","outputId":"167c5896-7e14-484f-ab97-63cd43b95ce7","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1716828442271,"user_tz":-540,"elapsed":794,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### depth2","metadata":{"id":"63lL7KUwY6D-"}},{"cell_type":"code","source":"depth_2_train = train_credit_bureau_a_2_0_mean.to_pandas()\ndepth_2_test = test_credit_bureau_a_2_0_mean.to_pandas()\n","metadata":{"id":"qPzVoFe4Y6D-","executionInfo":{"status":"ok","timestamp":1716828454648,"user_tz":-540,"elapsed":367,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_depth_0_depth_2_train = pd.merge(base_depth_0_train, depth_2_train, on='case_id', how='inner')\nbase_depth_0_depth_2_test = pd.merge(base_depth_0_test, depth_2_test, on='case_id', how='left')\n","metadata":{"id":"ZHfKegVFY6D-","executionInfo":{"status":"ok","timestamp":1716828459734,"user_tz":-540,"elapsed":2125,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_depth_0_depth_2_train","metadata":{"id":"_cR4lvMpY6D-","outputId":"f81cc861-7ae9-4d72-f20c-3e521ed4cd94","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1716828472077,"user_tz":-540,"elapsed":564,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. data train","metadata":{"id":"ArXkM5lRY6D-"}},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n","metadata":{"id":"8Ud0gla889mA","executionInfo":{"status":"ok","timestamp":1716828988771,"user_tz":-540,"elapsed":399,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = base_depth_0_depth_2_train\ntest_data = base_depth_0_depth_2_test","metadata":{"id":"zLCqECGc9DBK","executionInfo":{"status":"ok","timestamp":1716828568566,"user_tz":-540,"elapsed":3,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pl.DataFrame(train_data)\ntest_data = pl.DataFrame(test_data)\ntrain_data = train_data.to_pandas()\ntest_data = test_data.to_pandas()","metadata":{"id":"nKEWixtz9H6t","executionInfo":{"status":"ok","timestamp":1716828571786,"user_tz":-540,"elapsed":1397,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 훈련 및 테스트 데이터로 분할\ntrain_df, test_df = train_test_split(train_data, test_size=0.2, random_state=42)\ntrain_df = pl.DataFrame(train_df)\ntest_data = pl.DataFrame(test_data)\n","metadata":{"id":"9kQ0bLOT9JRb","executionInfo":{"status":"ok","timestamp":1716828576101,"user_tz":-540,"elapsed":2918,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5t69Wcos9XNL","executionInfo":{"status":"ok","timestamp":1716828601084,"user_tz":-540,"elapsed":484,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"d4873ec1-2463-449b-ae94-f8be706de359","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del depth_2_train\ndel depth_2_test","metadata":{"id":"ab37sd_S9YvC","executionInfo":{"status":"ok","timestamp":1716828632916,"user_tz":-540,"elapsed":375,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_dataframe(data):\n    # 데이터가 판다스 DataFrame 타입인지 확인\n    if isinstance(data, pd.DataFrame):\n        # 이미 판다스 DataFrame이면 그대로 반환\n        return data\n    else:\n        # 판다스 DataFrame으로 변환\n            converted_data = pd.DataFrame(data)\n            return converted_data\n","metadata":{"id":"FyrgKy2t9mUS","executionInfo":{"status":"ok","timestamp":1716828764175,"user_tz":-540,"elapsed":557,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = test_data.drop('case_id')\nX_train = train_df.drop(['case_id', 'target'])\ny_train = train_df['target']\nX_test = test_df.drop(columns=['case_id', 'target'])\ny_test = test_df['target']","metadata":{"id":"5eAZNFVZ9OJa","executionInfo":{"status":"ok","timestamp":1716828636151,"user_tz":-540,"elapsed":364,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = convert_to_dataframe(test_data)\nX_train = convert_to_dataframe(X_train)\ny_train = convert_to_dataframe(y_train)\nX_test = convert_to_dataframe(X_test)\ny_test = convert_to_dataframe(y_test)","metadata":{"id":"xJW4WkIV-AVb","executionInfo":{"status":"ok","timestamp":1716828793846,"user_tz":-540,"elapsed":398,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\n\n# K-fold 교차 검증 설정\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# PCA 설정\npca = PCA(n_components=2)\n\n# K-fold 교차 검증을 통한 모델 평가\naccuracy_scores = []\n\nfor train_index, val_index in kf.split(X_train):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n\n    # PCA를 훈련 데이터에 적용하여 차원 축소\n    X_train_pca = pca.fit_transform(X_train_fold)\n    X_val_pca = pca.transform(X_val_fold)\n\n    # LightGBM 모델 훈련\n    model_lgb = lgb.LGBMClassifier()\n    model_lgb.fit(X_train_pca, y_train_fold)\n\n    # 검증 데이터에 대한 예측 수행\n    y_val_pred = model_lgb.predict(X_val_pca)\n\n    # 정확도 계산\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    accuracy_scores.append(accuracy)\n\n# K-fold 교차 검증 결과 출력\nprint(f\"Accuracy scores for each fold: {accuracy_scores}\")\nprint(f\"Mean accuracy: {np.mean(accuracy_scores)}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZo_rXYc9igk","executionInfo":{"status":"ok","timestamp":1716828835249,"user_tz":-540,"elapsed":37574,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"d92a6583-07b2-40a6-9421-b074f1a92815","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = null_preprocessing(test_data)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JACcZjfF-Rwx","executionInfo":{"status":"ok","timestamp":1716828841819,"user_tz":-540,"elapsed":453,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"outputId":"6fa44427-db19-4d4b-c1f4-0f6bf42c867b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = pca.transform(test_data)\n","metadata":{"id":"ArlFu2sS-UqB","executionInfo":{"status":"ok","timestamp":1716828852785,"user_tz":-540,"elapsed":517,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_y = model_lgb.predict(test_data)","metadata":{"id":"j3PRBhPP-Wnd","executionInfo":{"status":"ok","timestamp":1716828861476,"user_tz":-540,"elapsed":776,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataPath = \"/kaggle/input/home-credit-credit-risk-model-stability/\"","metadata":{"id":"bFeu83jV-vIN","executionInfo":{"status":"ok","timestamp":1716829047224,"user_tz":-540,"elapsed":672,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv(dataPath + 'sample_submission.csv')\nsubmission['TARGET'] = test_y\nsubmission.to_csv('submission.csv', index=False)","metadata":{"id":"hbGAnqKv-Zmp","executionInfo":{"status":"ok","timestamp":1716829047679,"user_tz":-540,"elapsed":3,"user":{"displayName":"이다현","userId":"06548443428682955801"}},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"RlqohG0R-npl"},"outputs":[],"execution_count":null}]}